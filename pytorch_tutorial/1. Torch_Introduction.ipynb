{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b678d6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Core PyTorch Modules\n",
    "\n",
    "| Module | Description |\n",
    "| :--- | :--- |\n",
    "| **`torch`** | The core module providing multidimensional arrays (tensors) and mathematical operations on them. |\n",
    "| **`torch.autograd`** | Automatic differentiation engine that records operations on tensors to compute gradients for optimization. |\n",
    "| **`torch.nn`** | Provides a neural networks library, including layers, activations, loss functions, and utilities to build deep learning models. |\n",
    "| **`torch.optim`** | Contains optimization algorithms (optimizers) like SGD, Adam, and RMSprop used for training neural networks. |\n",
    "| **`torch.utils.data`** | Utilities for data handling, including the Dataset and DataLoader classes for managing and loading datasets efficiently. |\n",
    "| **`torch.jit`** | Supports Just-In-Time (JIT) compilation and TorchScript for optimizing models and enabling deployment without Python dependencies. |\n",
    "| **`torch.distributed`** | Tools for distributed training across multiple GPUs and machines, facilitating parallel computation. |\n",
    "| **`torch.cuda`** | Interfaces with NVIDIA CUDA to enable GPU acceleration for tensor computations and model training. |\n",
    "| **`torch.backends`** | Contains settings and allows control over backend libraries like cuDNN, MKL, and others for performance tuning. |\n",
    "| **`torch.multiprocessing`** | Utilities for parallelism using multiprocessing, similar to Python's multiprocessing module but with support for CUDA tensors. |\n",
    "| **`torch.quantization`** | Tools for model quantization to reduce model size and improve inference speed, especially on edge devices. |\n",
    "| **`torch.onnx`** | Supports exporting PyTorch models to the ONNX (Open Neural Network Exchange) format for interoperability with other frameworks and deployment. |\n",
    "\n",
    "\n",
    "### PyTorch Domain Libraries \n",
    "\n",
    "| Library | Description |\n",
    "| :--- | :--- |\n",
    "| **`torchvision`** | Provides datasets, model architectures, and image transformations for computer vision tasks. |\n",
    "| **`torchtext`** | Tools and datasets for natural language processing (NLP), including data preprocessing and vocabulary management. |\n",
    "| **`torchaudio`** | Utilities for audio processing tasks, including I/O, transforms, and pre-trained models for speech recognition. |\n",
    "| **`torcharrow`** | A library for accelerated data loading and preprocessing, especially for tabular and time series data (experimental). |\n",
    "| **`torchserve`** | A PyTorch model serving library that makes it easy to deploy trained models at scale in production environments. |\n",
    "| **`pytorch_lightning`** | A lightweight wrapper for PyTorch that simplifies the training loop and reduces boilerplate code, enabling scalable and reproducible models. |\n",
    "\n",
    "\n",
    "### Popular PyTorch Ecosystem Libraries \n",
    "\n",
    "| Library | Description |\n",
    "| :--- | :--- |\n",
    "| **Hugging Face Transformers** | Provides state-of-the-art pre-trained models for NLP tasks like text classification, translation, and question answering, built on PyTorch. |\n",
    "| **Fastai** | High-level library that simplifies training fast and accurate neural nets using modern best practices, built on top of PyTorch. |\n",
    "| **PyTorch Geometric** | Extension library for geometric deep learning, including graph neural networks and 3D data processing. |\n",
    "| **TorchMetrics** | A modular metrics API for PyTorch, compatible with PyTorch Lightning and provides standardized implementations of many common metrics. |\n",
    "| **Torch Elastic** | Enables dynamic scaling of PyTorch distributed training jobs, allowing for elasticity in resource management. |\n",
    "| **Optuna** | An automatic hyperparameter optimization software framework, integrating well with PyTorch for tuning models. |\n",
    "| **Catalyst** | Provides high-level features for training neural networks, focusing on reproducibility and fast experimentation. |\n",
    "| **Ignite** | High-level library to help with training neural networks in PyTorch, offering a lightweight engine for training and evaluating models. |\n",
    "| **AllenNLP** | An NLP research library built on PyTorch, designed to support researchers in deep learning for NLP. |\n",
    "| **Skorch** | A scikit-learn compatible wrapper for PyTorch that allows the use of PyTorch models with scikit-learn utilities and APIs. |\n",
    "| **PyTorch Forecasting** | High-level library for time series forecasting, making it easy to build, train, and evaluate complex models. |\n",
    "| **TensorBoard for PyTorch** | Allows visualization of training metrics, model graphs, and other useful data within TensorBoard for PyTorch models. |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
